{
	"name": "Spark Basics",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spwesyndem",
			"type": "BigDataPoolReference"
		},
		"targetSparkConfiguration": {
			"referenceName": "sparkConfiguration1",
			"type": "SparkConfigurationReference"
		},
		"sessionProperties": {
			"driverMemory": "56g",
			"driverCores": 8,
			"executorMemory": "56g",
			"executorCores": 8,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "8b433c6c-64ea-48bc-a19c-bee12f46f528"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/a864c3fe-e9f4-49af-88a9-dba5914d5ec2/resourceGroups/rg-we-syn-dem/providers/Microsoft.Synapse/workspaces/swwesyndem/bigDataPools/spwesyndem",
				"name": "spwesyndem",
				"type": "Spark",
				"endpoint": "https://swwesyndem.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spwesyndem",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 5,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30,
			"targetSparkConfiguration": "sparkConfiguration1"
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					}
				},
				"source": [
					"%%pyspark\r\n",
					"from pyspark.sql import SparkSession\r\n",
					"mssparkutils.credentials.help()\r\n",
					"#sc.getConf().getAll () \r\n",
					"# get(\"ADLSPath\")\r\n",
					"#print(spark.conf.get(\"spark.synapse.ADLSPath\"))\r\n",
					"#print(sc.getConf().contains(\"spark.synapse.ADLSPath\"))\r\n",
					"\r\n",
					"#mssparkutils.credentials.getSecret(\"AzureKeyVault\",\"test\")\r\n",
					"mssparkutils.credentials.getSecret(\"pvlab-cda48b-keyvault\",\"test\")"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\r\n",
					" from pyspark.sql.types import *\r\n",
					" from pyspark.sql.functions import *\r\n",
					"\r\n",
					" orderSchema = StructType([\r\n",
					"     StructField(\"SalesOrderNumber\", StringType()),\r\n",
					"     StructField(\"SalesOrderLineNumber\", IntegerType()),\r\n",
					"     StructField(\"OrderDate\", DateType()),\r\n",
					"     StructField(\"CustomerName\", StringType()),\r\n",
					"     StructField(\"Email\", StringType()),\r\n",
					"     StructField(\"Item\", StringType()),\r\n",
					"     StructField(\"Quantity\", IntegerType()),\r\n",
					"     StructField(\"UnitPrice\", FloatType()),\r\n",
					"     StructField(\"Tax\", FloatType())\r\n",
					"     ])\r\n",
					"\r\n",
					" df = spark.read.load('abfss://sales@dlwesyndem.dfs.core.windows.net/orders/*.csv', format='csv', schema=orderSchema)\r\n",
					" display(df.limit(100))"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					" df.printSchema()"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					" customers = df.select(\"CustomerName\", \"Email\").where(df['Item']=='Road-250 Red, 52')\r\n",
					" print(customers.count())\r\n",
					" print(customers.distinct().count())\r\n",
					" display(customers.distinct())"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					" productSales = df.select(\"Item\", \"Quantity\").groupBy(\"Item\").sum()\r\n",
					" display(productSales)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					" yearlySales = df.select(year(\"OrderDate\").alias(\"Year\")).groupBy(\"Year\").count().orderBy(\"Year\")\r\n",
					" display(yearlySales)"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					" df.createOrReplaceTempView(\"salesorders\")\r\n",
					"\r\n",
					" spark_df = spark.sql(\"SELECT * FROM salesorders\")\r\n",
					" display(spark_df)"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					" %%sql\r\n",
					" SELECT YEAR(OrderDate) AS OrderYear,\r\n",
					"        SUM((UnitPrice * Quantity) + Tax) AS GrossRevenue\r\n",
					" FROM salesorders\r\n",
					" GROUP BY YEAR(OrderDate)\r\n",
					" ORDER BY OrderYear;"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					" sqlQuery = \"SELECT CAST(YEAR(OrderDate) AS CHAR(4)) AS OrderYear, \\\r\n",
					"                 SUM((UnitPrice * Quantity) + Tax) AS GrossRevenue \\\r\n",
					"             FROM salesorders \\\r\n",
					"             GROUP BY CAST(YEAR(OrderDate) AS CHAR(4)) \\\r\n",
					"             ORDER BY OrderYear\"\r\n",
					" df_spark = spark.sql(sqlQuery)\r\n",
					" df_spark.show()"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					" # Clear the plot area\r\n",
					" plt.clf()\r\n",
					"\r\n",
					" # Create a figure for 2 subplots (1 row, 2 columns)\r\n",
					" fig, ax = plt.subplots(1, 2, figsize = (10,4))\r\n",
					"\r\n",
					" # Create a bar plot of revenue by year on the first axis\r\n",
					" ax[0].bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'], color='orange')\r\n",
					" ax[0].set_title('Revenue by Year')\r\n",
					"\r\n",
					" # Create a pie chart of yearly order counts on the second axis\r\n",
					" yearly_counts = df_sales['OrderYear'].value_counts()\r\n",
					" ax[1].pie(yearly_counts)\r\n",
					" ax[1].set_title('Orders per Year')\r\n",
					" ax[1].legend(yearly_counts.keys().tolist())\r\n",
					"\r\n",
					" # Add a title to the Figure\r\n",
					" fig.suptitle('Sales Data')\r\n",
					"\r\n",
					" # Show the figure\r\n",
					" plt.show()"
				],
				"execution_count": 20
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					" import seaborn as sns\r\n",
					"\r\n",
					" # Clear the plot area\r\n",
					" plt.clf()\r\n",
					"\r\n",
					" # Create a bar chart\r\n",
					" ax = sns.barplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\r\n",
					" plt.show()"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					" # Clear the plot area\r\n",
					" plt.clf()\r\n",
					"\r\n",
					" # Create a bar chart\r\n",
					" ax = sns.lineplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\r\n",
					" plt.show()"
				],
				"execution_count": 22
			}
		]
	}
}